{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62c39a-0f04-4ec7-b4d6-4ee4d6973007",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!pip install pytrec-eval\n",
    "#!pip install ipywidgets\n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b2faa-25f7-44dd-8a8e-3c8e939a3627",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736e6e0-8bc2-4c4a-bbfb-01f6f28dabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_search_connect \n",
    "client=open_search_connect.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcc66f-082e-460b-a9ea-c9d6220b742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "def search_opensearch(query, k=10):\n",
    "    body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": {\n",
    "                    \"query\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    res = client.search(index=INDEX_NAME, body=body)\n",
    "  #  print(res[\"hits\"][\"hits\"])\n",
    "    out = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40014c5a-88fc-4e6c-a0a9-bbfe85b73e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_opensearch(\"amber urine\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd88af9-eff5-40ca-89b3-776d43abfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified  return value for running  pytrec_eval \n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "def search_opensearch_reranked(query, k):\n",
    "    body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": {\n",
    "                    \"query\": query,\n",
    "                    \"analyzer\": \"english\"\n",
    "\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    res = client.search(index=INDEX_NAME, body=body)\n",
    "    out = [(hit[\"_source\"][\"doc_id\"], hit[\"_source\"][\"text\"]) for hit in res[\"hits\"][\"hits\"]]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5cacd-d3a5-4a8f-a683-f49df6bce772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b2a7b-0bdf-4265-bd55-6ea647ae5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# modified  return value for running  pytrec_eval \n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "def hybrid_opensearch_reranked(query, k):\n",
    "    query_vector = embedding_model.encode(query).tolist()\n",
    " \n",
    "    body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"should\"{\n",
    "            \"match\": {\n",
    "                \"text\": {\n",
    "                    \"query\": query,\n",
    "                    \"analyzer\": \"english\"\n",
    "\n",
    "                }\n",
    "            },\n",
    "                                \n",
    "             \"knn\": {\n",
    "                            \"text_vector\": {\n",
    "                                \"vector\": query_vector,\n",
    "                                \"k\": size,\n",
    "                                \"boost\": 3.0\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    res = client.search(index=INDEX_NAME, body=body)\n",
    "#   print(res[\"hits\"][\"hits\"])\n",
    "   # out = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "    out = [(hit[\"_source\"][\"doc_id\"], hit[\"_source\"][\"text\"]) for hit in res[\"hits\"][\"hits\"]]\n",
    "    #print(\"----\")\n",
    "    # for index,hit in enumerate(out):\n",
    "    #     print(index+1,\"--\", hit[0],\"----\", hit[1][:100])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644b39d-510c-43c7-9b4a-8b4894532903",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_docs = search_opensearch_reranked(\"amber urine\",1)\n",
    "print(single_docs)\n",
    "#rerank_with_cross_encoder(\"amber urine\",single_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345edc2-4845-4405-be59-44dc2894ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fad0d4-8207-4ef6-aed6-adc6a38d4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"how tall is mount everest?\"\n",
    "# doc = \"Mount Everest is 8848 meters high.\"\n",
    "\n",
    "# score = model.predict([(query, doc)])\n",
    "# print(score)  # e.g. [0.92]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64a8af-8431-46c5-a147-eb3b1175a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_cross_encoder(query, docs,rerank_count):\n",
    "    pairs = [(query, text) for _, text in docs[:rerank_count]]\n",
    "    scores = model.predict(pairs)\n",
    "\n",
    "    reranked = sorted(\n",
    "        zip(docs, scores),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return [(doc_id, text, score) for ((doc_id, text), score) in reranked]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99794fd4-c773-4d9a-9a5a-d6121c2cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \" )what was the immediate impact of the success of the manhattan project? \"\n",
    "# result_docs = search_opensearch(query, k=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8abf6-c0bb-4f90-9e32-d1a7370a3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reranked = rerank_with_cross_encoder(query, result_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481190b-a968-4aac-8e74-d21830057c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "dataset = ir_datasets.load(\"msmarco-passage/train/split200-train\")\n",
    "queries = {q.query_id: q.text for q in dataset.queries_iter()}\n",
    "qrels = dataset.qrels_dict()   # âœ… use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1166a73-57e5-4b60-9fc4-048edafdf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluates opensearch results against the rlevant documents in qrel_dict\n",
    "import pytrec_eval\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "run = {}\n",
    "\n",
    "for qid, query_text in tqdm(list(queries.items())[:20]):  # limit for speed\n",
    "    docs = search_opensearch(query_text, k=20)\n",
    "    #print(docs)\n",
    "    #    print(qid, query_text) \n",
    "    \n",
    "    run[qid] = {doc_id: 1.0 for doc_id in docs}  # dummy score\n",
    "    # for doc_id in reranked:\n",
    "    #    print(doc_id[0])\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "    qrels,\n",
    "    {\"map\", \"ndcg_cut_10\", \"recall_10\", \"P_10\"}\n",
    ")\n",
    "\n",
    "results = evaluator.evaluate(run)\n",
    "\n",
    "# average over queries\n",
    "avg = {m: 0 for m in [\"map\", \"ndcg_cut_10\", \"recall_10\", \"P_10\"]}\n",
    "\n",
    "for qid in results:\n",
    "    for m in avg:\n",
    "        avg[m] += results[qid][m]\n",
    "\n",
    "for m in avg:\n",
    "    avg[m] /= len(results)\n",
    "\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bbb76-ef68-47ff-99cf-83df69ab1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'map': 0.021794871794871794, 'ndcg_cut_10': 0.028711770538226204, 'recall_10': 0.06666666666666667, 'P_10': 0.006666666666666667}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47734070-56ca-4ecc-9388-3a716302ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate \"run\" for evaluations with re-ranking\n",
    "from tqdm import tqdm\n",
    "run = {}\n",
    "\n",
    "for qid, query_text in tqdm(list(queries.items())[:500]):  # limit for speed\n",
    "    if(qid in qrels):\n",
    "        docs = search_opensearch_reranked(query_text,100)\n",
    "        reranked_docs = rerank_with_cross_encoder(query_text, docs,100)\n",
    "        \n",
    "        run[qid] = {\n",
    "        doc_id: float(score)\n",
    "        for doc_id, _, score in reranked_docs[:10]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d4025-837f-4922-96f3-7a3b8f3d3481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels,{\"map\", \"ndcg_cut_10\", \"recall_10\", \"P_10\",\"recip_rank\"})\n",
    "results = evaluator.evaluate(run)\n",
    "\n",
    "# average over queries\n",
    "avg = {m: 0 for m in [\"map\", \"ndcg_cut_10\", \"recall_10\", \"P_10\",\"recip_rank\"]}\n",
    "\n",
    "for qid in results:\n",
    "    for m in avg:\n",
    "        avg[m] += results[qid][m]\n",
    "\n",
    "for m in avg:\n",
    "    avg[m] /= len(results)\n",
    "    #print(avg)\n",
    "\n",
    "\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed37b05-4700-44a7-98e6-2059043b3290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4c15b-407c-4e52-930d-a26b2518608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540244e-f6f4-469b-954c-f58d8d08c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a5ece-890f-41a7-bd74-2f4badfded7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
